import chromadb
from langchain_community.embeddings import DashScopeEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from typing import List, Dict
from config import config
from processors.data_processor import ProcessedDocument

class FiveToolsVectorStore:
    def __init__(self, persist_directory: str = "./chroma_db"):
        # ä½¿ç”¨é˜¿é‡Œäº‘text-embedding-v4
        self.embeddings = DashScopeEmbeddings(
            model=config.EMBEDDING_MODEL,
            dashscope_api_key=config.DASHSCOPE_API_KEY,
            dimension=config.EMBEDDING_DIMENSION,  # ä½¿ç”¨1024ç»´åº¦å¹³è¡¡æ€§èƒ½å’Œæ•ˆæœ
            output_type="dense"  # ä½¿ç”¨ç¨ å¯†å‘é‡
        )
        
        # åˆå§‹åŒ–ChromaDB
        self.client = chromadb.PersistentClient(path=persist_directory)
        self.collection_name = "5etools_knowledge_v4"
        
        # æ–‡æœ¬åˆ†å‰²å™¨ - é’ˆå¯¹8192 Tokenä¼˜åŒ–
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=2000,  # é€‚é…8192 Tokené™åˆ¶
            chunk_overlap=200,
            length_function=len,
        )
        
    def build_index(self, documents: List[ProcessedDocument]) -> bool:
        """æ„å»ºå‘é‡ç´¢å¼•"""
        try:
            # é‡å»ºé›†åˆ
            try:
                self.client.delete_collection(self.collection_name)
            except:
                pass
            
            collection = self.client.create_collection(
                name=self.collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            
            # æ‰¹é‡å¤„ç† - éµå¾ªAPIé™åˆ¶ï¼ˆæ¯æ‰¹æœ€å¤š10æ¡ï¼‰
            batch_size = 8  # ä¿å®ˆè®¾ç½®ï¼Œç¡®ä¿ç¨³å®šæ€§
            total_chunks = 0
            
            for i in range(0, len(documents), batch_size):
                batch_docs = documents[i:i+batch_size]
                
                # å‡†å¤‡æ‰¹é‡æ•°æ®
                texts = []
                metadatas = []
                ids = []
                
                for doc in batch_docs:
                    # åˆ†å‰²é•¿æ–‡æ¡£
                    chunks = self.text_splitter.split_text(doc.content)
                    
                    for j, chunk in enumerate(chunks):
                        chunk_id = f"{doc.id}_chunk_{j}"
                        texts.append(chunk)
                        metadatas.append({
                            'document_id': doc.id,
                            'title': doc.title,
                            'category': doc.category,
                            'chunk_index': j,
                            **doc.metadata
                        })
                        ids.append(chunk_id)
                
                if texts:
                    # ä½¿ç”¨text-embedding-v4æ‰¹é‡åµŒå…¥
                    embeddings = self.embeddings.embed_documents(texts)
                    
                    collection.add(
                        embeddings=embeddings,
                        documents=texts,
                        metadatas=metadatas,
                        ids=ids
                    )
                    
                    total_chunks += len(texts)
                    print(f"âœ… å·²å¤„ç† {i+len(batch_docs)}/{len(documents)} ä¸ªæ–‡æ¡£ï¼Œå…± {total_chunks} ä¸ªå‘é‡å—")
            
            print(f"ğŸ‰ å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼å…±ç”Ÿæˆ {total_chunks} ä¸ªå‘é‡å—")
            return True
            
        except Exception as e:
            print(f"âŒ å‘é‡ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
            return False
    
    def search(self, query: str, category_filter: str = None, n_results: int = 5) -> List[Dict]:
        """è¯­ä¹‰æœç´¢"""
        try:
            collection = self.client.get_collection(self.collection_name)
            
            # ä½¿ç”¨text-embedding-v4è¿›è¡ŒæŸ¥è¯¢åµŒå…¥
            query_embedding = self.embeddings.embed_query(query)
            
            # æ„å»ºè¿‡æ»¤æ¡ä»¶
            where_filter = {}
            if category_filter:
                where_filter["category"] = category_filter
            
            # æ‰§è¡Œå‘é‡æœç´¢
            results = collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                where=where_filter if where_filter else None,
                include=["documents", "metadatas", "distances"]
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for i in range(len(results['documents'][0])):
                formatted_results.append({
                    'content': results['documents'][0][i],
                    'metadata': results['metadatas'][0][i],
                    'score': 1 - results['distances'][0][i]  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return [] 